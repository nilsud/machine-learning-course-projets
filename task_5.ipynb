{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import clf as clf\n",
    "import estimator as estimator\n",
    "#imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import __all__, svm\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get csv file and convert to dataframe\n",
    "virus_df = pd.read_csv(\"hw5_data.csv\", sep=',')\n",
    "virus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = virus_df['target']\n",
    "X = virus_df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split dataframe two part, target and feature\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3749, 1799), (1250, 1799))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove highly correlated features\n",
    "correlated_features = set()\n",
    "correlation_matrix = virus_df.corr()\n",
    "for i in range(len(correlation_matrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "X_train.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Cross Validation Mean Accuracy:  0.514808722741433\n",
      "Test score:  0.5168\n"
     ]
    }
   ],
   "source": [
    "#cross validation and test score of logistic regression\n",
    "ss = StandardScaler()\n",
    "X_train_scale = ss.fit_transform(X_train)\n",
    "print(\"LR Cross Validation Mean Accuracy: \", cross_val_score(lr, X_train_scale, y_train, cv=5).mean())\n",
    "lr.fit(X_train_scale, y_train)\n",
    "\n",
    "\n",
    "X_test_scale = ss.fit_transform(X_test)\n",
    "print('Test score: ', sum(lr.predict(X_test_scale)==y_test)/len(y_test) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Hyperparameter Search (Grid Search) and feature selections methods applying on variety algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random forest classifier with grid search and feature selection (RFE)\n",
    "pipe_rfe_rfc =  Pipeline([\n",
    "    ('rfe', RFE(estimator=RandomForestClassifier())),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid_rfc = [{\n",
    "    'clf__max_depth': [2, 3, 4],\n",
    "    'clf__max_features': [2, 3, 4, 5, 6]\n",
    "}]\n",
    "#\n",
    "# Create an instance of GridSearch Cross-validation estimator\n",
    "#\n",
    "grid_rfe_rfc = GridSearchCV(estimator=pipe_rfe_rfc,\n",
    "                     param_grid = param_grid_rfc,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10,\n",
    "                     refit=True,\n",
    "                     n_jobs=1)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "grid_rfe_rfc = grid_rfe_rfc.fit(X_train, y_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(grid_rfe_rfc.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "#print(grid_rfe_rfc.best_params_)\n",
    "\n",
    "# Print the test score of the best model\n",
    "clfRFC = grid_rfe_rfc.best_estimator_\n",
    "print('Test accuracy: %.3f' % clfRFC.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "validation and test set performances with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LDA(n_components=4)\n",
    "lda.fit(X_train_scale, y_train)\n",
    "X_train_lda = lda.transform(X_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline for training a logistic regression classifier using linear discriminant analysis (LDA).\n",
    "pipe_lda_lr= Pipeline([('lda', LDA()),\n",
    "              ('model', LogisticRegression(solver='liblinear', max_iter=100000), 'scaler', StandardScaler())\n",
    "             ])\n",
    "\n",
    "params = {'model__C': [0.1, 1, 10], 'lda__n_components': [2, 3, 4]}\n",
    "\n",
    "grid_lda_lr = GridSearchCV(pipe_lda_lr, param_grid=params, scoring='accuracy', cv=5, refit=True)\n",
    "grid_lda_lr.fit(X_train_scale, y_train)\n",
    "\n",
    "#print(\"Best parameters: {}\".format(grid_lda_lr.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_lda_lr.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_lda_lr.score(X), y)\n",
    "print(\"Best estimator:\\n{}\".format(grid_lda_lr.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from https://makeabilitylab.github.io/physcomp/signals/FeatureSelectionAndHyperparameterTuning/index.html\n",
    "\n",
    "#Defining a pipeline for training a classifier using a combination of feature scaling, feature selection, and classification.\n",
    "scaler = StandardScaler()\n",
    "feature_selector = SelectKBest(k=5)\n",
    "pipeline = Pipeline([('scaler', scaler), ('selector', feature_selector), ('estimator', clf)])\n",
    "\n",
    "# Setup our hyperparameter ranges for the grid search.\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "# The hierarchy in the pipeline can be reached using double underscore(‘__’)\n",
    "scaler = StandardScaler()\n",
    "feature_selector = SelectKBest(k=5)\n",
    "pipeline = Pipeline([('scaler', scaler), ('selector', feature_selector), ('estimator', clf)])\n",
    "\n",
    "# Setup our hyperparameter ranges for the grid search.\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "# The hierarchy in the pipeline can be reached using double underscore(‘__’)\n",
    "param_grid = [\n",
    "  {'selector__k': [4, 5], 'estimator__degree': [1, 2, 3], 'estimator__gamma': gamma_range, 'estimator__kernel': ['poly']},\n",
    "  {'estimator__C': C_range, 'estimator__kernel': ['linear']},\n",
    "  {'estimator__C': C_range, 'estimator__gamma': gamma_range, 'estimator__kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)\n",
    "clf = svm.SVC()\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=skf, return_train_score=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "#print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_search.score(X), y)\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Define a pipeline that consists of RFE and a logistic regression classifier\n",
    "pipe_rfe_lr = Pipeline([('rfe', RFE(estimator=LogisticRegression(max_iter=1000000))), ('scaler', StandardScaler()),\n",
    "                    ('clf', LogisticRegression(max_iter=100000))])\n",
    "\n",
    "# Use grid search to fine-tune the hyperparameters of the logistic regression classifier\n",
    "param_grid = {'rfe__estimator__C': [0.1, 1, 10],\n",
    "              'clf__C': [0.1, 1, 10]}\n",
    "grid_rfe_lr = GridSearchCV(pipe_rfe_lr, param_grid, cv=10)\n",
    "grid_rfe_lr.fit(X_train_scale, y_train)\n",
    "\n",
    "\n",
    "#print(\"Best parameters: {}\".format(grid_rfe_lr.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_rfe_lr.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_rfe_lr.score(X), y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a pipeline that consists of RFE and a decision tree classifier\n",
    "# create pipeline\n",
    "pipe_rfe_dt = Pipeline([('rfe', RFE(estimator=DecisionTreeClassifier())),\n",
    "                    ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "# Use grid search to fine-tune the hyperparameters of the decision tree classifier\n",
    "param_grid = {'rfe__estimator__criterion': ['gini', 'entropy'],\n",
    "              'clf__criterion': ['gini', 'entropy'],\n",
    "              'clf__min_samples_leaf': [1, 2, 3],\n",
    "    'clf__max_depth': [1, 2, 3]}\n",
    "\n",
    "\n",
    "\n",
    "grid_rfe_dt = GridSearchCV(pipe_rfe_dt, param_grid, cv=10)\n",
    "grid_rfe_dt.fit(X_train, y_train)\n",
    "\n",
    "#print(\"Best parameters: {}\".format(grid_rfe_dt.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_rfe_dt.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_rfe_dt.score(X), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grid search and the GenericUnivariateSelect filter method to perform feature selection on a logistic regression classifier\n",
    "select = GenericUnivariateSelect(score_func=mutual_info_classif, mode=\"k_best\", param=5)\n",
    "pipe_unisel_lr = Pipeline([\n",
    "      (\"MutualInfo\", select),\n",
    "      (\"LR\", LogisticRegression(solver='liblinear', max_iter=100000), 'scaler', StandardScaler() )\n",
    "])\n",
    "\n",
    "param_grid = {'LR__C': [0.1, 1, 10]}\n",
    "\n",
    "grid_unisel_lr = GridSearchCV(pipe_unisel_lr, param_grid, cv=10)\n",
    "grid_unisel_lr.fit(X_train_scale, y_train)\n",
    "\n",
    "#print(\"Best parameters: {}\".format(grid_unisel_lr.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_unisel_lr.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_unisel_lr.score(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from https://vitalflux.com/grid-search-explained-python-sklearn-examples/\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Grid search and recursive feature elimination (RFE) to perform feature selection and hyperparameter tuning on a support vector classifier\n",
    "pipe_rfe_svc = Pipeline([('rfe', RFE(estimator=SVC(random_state=1))),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('clf', SVC(random_state=1))])\n",
    "\n",
    "# Define a pipeline that consists of RFE and a logistic regression classifier\n",
    "param_grid = [{                    'clf__C': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
    "                    'clf__kernel': ['linear']\n",
    "                  },\n",
    "                 {\n",
    "                    'clf__C': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
    "                    'clf__gamma': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 10.0],\n",
    "                    'clf__kernel': ['rbf']\n",
    "                 }]\n",
    "\n",
    "# Create an instance of GridSearch Cross-validation estimator\n",
    "#\n",
    "grid_rfe_svc = GridSearchCV(pipe_rfe_svc,\n",
    "                     param_grid = param_grid,\n",
    "                     scoring='accuracy',\n",
    "                     cv=10,\n",
    "                     refit=True,\n",
    "                     n_jobs=1)\n",
    "\n",
    "grid_rfe_svc.fit(X_train, y_train)\n",
    "\n",
    "#print(\"Best parameters: {}\".format(grid_rfe_svc.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_rfe_svc.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_rfe_svc.score(X), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grid search to perform feature selection and hyperparameter tuning on a k-nearest neighbors (KNN) classifier\n",
    "pipe_kbest_kneigh =Pipeline(memory=None,\n",
    "         steps=[('scaler',\n",
    "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
    "                ('selector',\n",
    "                 SelectKBest(k=5)),\n",
    "                ('classifier',\n",
    "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
    "                                      metric='minkowski', metric_params=None,\n",
    "                                      n_jobs=None, n_neighbors=3, p=2,\n",
    "                                      weights='distance'))],verbose=False)\n",
    "\n",
    "param_grid = [{'selector__k': [5, 10, 20, 30]},\n",
    "              {'classifier': [KNeighborsClassifier()],'classifier__n_neighbors': [3, 7, 11],\n",
    "              'classifier__weights': ['uniform', 'distance']}]\n",
    "\n",
    "grid_k_best_kneigh = GridSearchCV(pipe_kbest_kneigh, param_grid, cv=10, verbose=0)\n",
    "grid_k_best_kneigh.fit(X, y)\n",
    "#print(\"Best parameters: {}\".format(grid_k_best_kneigh.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_k_best_kneigh.best_score_))\n",
    "print('Test score:' )\n",
    "print( grid_k_best_kneigh.score(X), y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.60 (+/- 0.01) [Logistic Regression]\n",
      "Accuracy 0.47 (+/- 0.00) [Decision Tree]\n",
      "Accuracy 0.24 (+/- 0.03) [k-Nearest Neighbors]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf1 = LogisticRegression(penalty='l2', C=0.001, solver='lbfgs', random_state=0, max_iter=100000)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1, criterion='entropy', random_state=1)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()),('logreg', clf1)])\n",
    "pipe2 = Pipeline([('scaler', StandardScaler()),('tree', clf2)])\n",
    "pipe3 = Pipeline([('scaler', StandardScaler()),('knn', clf3)])\n",
    "\n",
    "labs = ['Logistic Regression', 'Decision Tree', 'k-Nearest Neighbors']\n",
    "clfs = [pipe1, pipe2, pipe3]\n",
    "clfs = zip(labs, clfs)\n",
    "\n",
    "for lab, clf in clfs:\n",
    "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, scoring='accuracy')\n",
    "    print(f'Accuracy {scores.mean():.2f} (+/- {scores.std():.2f}) [{lab}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.40 (+/- 0.01) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "ems = [('lr', pipe1),('dt', pipe2),('knn', pipe3)]\n",
    "clf4 = VotingClassifier(estimators= ems, weights=None, voting='soft')\n",
    "\n",
    "scores = cross_val_score(estimator=clf4, X=X_train, y=y_train, cv=5, scoring='accuracy')\n",
    "print(f'Accuracy {scores.mean():.2f} (+/- {scores.std():.2f}) [Ensemble]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virus :\n",
      "\t Vote(DTx20) 0.8488\n",
      "\t Vote(LRx20) 0.6008\n",
      "\t Vote(RFx20) 0.9064\n",
      "\t Vote(NNx20) 0.7464\n",
      "\t Bag(DTx20) 0.908\n",
      "\t\tOOB: 0.8941050946919178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilsu\\PycharmProjects\\pythonProject11\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  UserWarning,\n",
      "C:\\Users\\nilsu\\PycharmProjects\\pythonProject11\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  UserWarning,\n",
      "C:\\Users\\nilsu\\PycharmProjects\\pythonProject11\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  UserWarning,\n",
      "C:\\Users\\nilsu\\PycharmProjects\\pythonProject11\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  UserWarning,\n",
      "C:\\Users\\nilsu\\PycharmProjects\\pythonProject11\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Bag(RFx20) 0.9064\n",
      "\t Bag(LRx20) 0.6672\n",
      "\t\tOOB: 0.6521739130434783\n",
      "\t Bag(NNx20) 0.7688\n",
      "\t\tOOB: 0.7444651907175247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifiers = []\n",
    "names = []\n",
    "\n",
    "classifiers.append( VotingClassifier([ (str(x), DecisionTreeClassifier() ) for x in range(20) ]) )\n",
    "names.append(\"Vote(DTx20)\")\n",
    "\n",
    "classifiers.append( VotingClassifier([ (str(x), LogisticRegression(solver='liblinear', multi_class='auto', max_iter=100000) ) for x in range(20)  ]) )\n",
    "names.append(\"Vote(LRx20)\")\n",
    "\n",
    "classifiers.append( VotingClassifier([ (str(x), RandomForestClassifier( oob_score=True) ) for x in range(20)  ]) )\n",
    "names.append(\"Vote(RFx20)\")\n",
    "\n",
    "classifiers.append( VotingClassifier([ (str(x), KNeighborsClassifier() ) for x in range(20) ]) )\n",
    "names.append(\"Vote(NNx20)\")\n",
    "\n",
    "classifiers.append( BaggingClassifier(DecisionTreeClassifier(), n_estimators=20, max_samples=0.6, oob_score=True) )\n",
    "names.append(\"Bag(DTx20)\")\n",
    "\n",
    "classifiers.append( BaggingClassifier(RandomForestClassifier(n_estimators=20, oob_score=True)) )\n",
    "names.append(\"Bag(RFx20)\")\n",
    "\n",
    "classifiers.append( BaggingClassifier(LogisticRegression(solver='liblinear', multi_class='auto', max_iter=100000), n_estimators=20, max_samples=0.6, oob_score=True) )\n",
    "names.append(\"Bag(LRx20)\")\n",
    "classifiers.append( BaggingClassifier(KNeighborsClassifier(), n_estimators=20, max_samples=0.6, oob_score=True) )\n",
    "names.append(\"Bag(NNx20)\")\n",
    "\n",
    "\n",
    "print(\"virus\", \":\")\n",
    "for model, m_name in zip(classifiers, names):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"\\t\", m_name, accuracy_score(y_test, model.predict(X_test)))\n",
    "    if \"oob_score_\" in dir(model):\n",
    "      print(\"\\t\\tOOB:\", model.oob_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I aimed this in this code, finding cross validation scores of searching and classifier methods thus bigger cross validation scores will be good for our classification of dataset. In the ensemble methods, bigger accuracy value of classification method is better for our dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
